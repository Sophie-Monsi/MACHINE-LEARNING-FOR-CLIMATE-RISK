{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eaeea656",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting py7zr\n",
      "  Downloading py7zr-1.0.0-py3-none-any.whl.metadata (17 kB)\n",
      "Requirement already satisfied: pandas in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (2.2.2)\n",
      "Collecting texttable (from py7zr)\n",
      "  Downloading texttable-1.7.0-py2.py3-none-any.whl.metadata (9.8 kB)\n",
      "Collecting pycryptodomex>=3.20.0 (from py7zr)\n",
      "  Downloading pycryptodomex-3.23.0-cp37-abi3-win_amd64.whl.metadata (3.5 kB)\n",
      "Collecting brotli>=1.1.0 (from py7zr)\n",
      "  Downloading brotli-1.2.0-cp312-cp312-win_amd64.whl.metadata (6.3 kB)\n",
      "Requirement already satisfied: psutil in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from py7zr) (5.9.0)\n",
      "Collecting pyzstd>=0.16.1 (from py7zr)\n",
      "  Downloading pyzstd-0.18.0-cp312-cp312-win_amd64.whl.metadata (2.6 kB)\n",
      "Collecting pyppmd<1.3.0,>=1.1.0 (from py7zr)\n",
      "  Downloading pyppmd-1.2.0-cp312-cp312-win_amd64.whl.metadata (5.6 kB)\n",
      "Collecting pybcj<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading pybcj-1.0.6-cp312-cp312-win_amd64.whl.metadata (3.8 kB)\n",
      "Collecting multivolumefile>=0.2.3 (from py7zr)\n",
      "  Downloading multivolumefile-0.2.3-py3-none-any.whl.metadata (6.3 kB)\n",
      "Collecting inflate64<1.1.0,>=1.0.0 (from py7zr)\n",
      "  Downloading inflate64-1.0.3-cp312-cp312-win_amd64.whl.metadata (4.5 kB)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from pandas) (1.26.4)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from pandas) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: typing-extensions>=4.13.2 in c:\\users\\lisaw\\anaconda3\\lib\\site-packages (from pyzstd>=0.16.1->py7zr) (4.13.2)\n",
      "Downloading py7zr-1.0.0-py3-none-any.whl (69 kB)\n",
      "   ---------------------------------------- 0.0/69.7 kB ? eta -:--:--\n",
      "   ---------------------------------------- 69.7/69.7 kB 3.7 MB/s eta 0:00:00\n",
      "Downloading brotli-1.2.0-cp312-cp312-win_amd64.whl (369 kB)\n",
      "   ---------------------------------------- 0.0/369.1 kB ? eta -:--:--\n",
      "   ------------------------------------ --- 337.9/369.1 kB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 369.1/369.1 kB 5.8 MB/s eta 0:00:00\n",
      "Downloading inflate64-1.0.3-cp312-cp312-win_amd64.whl (35 kB)\n",
      "Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n",
      "Downloading pybcj-1.0.6-cp312-cp312-win_amd64.whl (24 kB)\n",
      "Downloading pycryptodomex-3.23.0-cp37-abi3-win_amd64.whl (1.8 MB)\n",
      "   ---------------------------------------- 0.0/1.8 MB ? eta -:--:--\n",
      "   ----- ---------------------------------- 0.2/1.8 MB 5.0 MB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 0.5/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------ --------------------- 0.8/1.8 MB 6.6 MB/s eta 0:00:01\n",
      "   ------------------------- -------------- 1.2/1.8 MB 6.7 MB/s eta 0:00:01\n",
      "   ---------------------------------- ----- 1.5/1.8 MB 7.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 1.8/1.8 MB 6.8 MB/s eta 0:00:00\n",
      "Downloading pyppmd-1.2.0-cp312-cp312-win_amd64.whl (46 kB)\n",
      "   ---------------------------------------- 0.0/46.6 kB ? eta -:--:--\n",
      "   ---------------------------------------- 46.6/46.6 kB ? eta 0:00:00\n",
      "Downloading pyzstd-0.18.0-cp312-cp312-win_amd64.whl (249 kB)\n",
      "   ---------------------------------------- 0.0/249.8 kB ? eta -:--:--\n",
      "   ---------------------------------------- 249.8/249.8 kB 7.7 MB/s eta 0:00:00\n",
      "Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n",
      "Installing collected packages: texttable, brotli, pyzstd, pyppmd, pycryptodomex, pybcj, multivolumefile, inflate64, py7zr\n",
      "  Attempting uninstall: brotli\n",
      "    Found existing installation: Brotli 1.0.9\n",
      "    Uninstalling Brotli-1.0.9:\n",
      "      Successfully uninstalled Brotli-1.0.9\n",
      "Successfully installed brotli-1.2.0 inflate64-1.0.3 multivolumefile-0.2.3 py7zr-1.0.0 pybcj-1.0.6 pycryptodomex-3.23.0 pyppmd-1.2.0 pyzstd-0.18.0 texttable-1.7.0\n"
     ]
    }
   ],
   "source": [
    "! pip install py7zr pandas\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a0b22d27",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import gzip\n",
    "import py7zr\n",
    "import io\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "64638c8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Fonction pour récupérer les données d'un fichier csv.gz ( pour les données météorologiques )\n",
    "def recuperer_donnees_gz(dataset_id, fichier_csv, sep):\n",
    "    \"\"\"\n",
    "    Cette fonction télécharge les données d'un fichier CSV.GZ à partir d'une URL et les charge dans un DataFrame pandas.\n",
    "    \n",
    "    Paramètres:\n",
    "    dataset_id (str): identifiant du fichier CSV.GZ.\n",
    "    fichier_csv (str): Le nom du fichier CSV.GZ à enregistrer localement.\n",
    "    sep ( str ) : le séparateur à utiliser\n",
    "    \n",
    "    Retourne:\n",
    "    DataFrame: Un DataFrame pandas contenant les données du fichier CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    # URL de base pour accéder à l'API\n",
    "    base_api = \"https://www.data.gouv.fr/api/1/\"\n",
    "\n",
    "    # Chemin pour accéder aux enregistrements du dataset\n",
    "    key_api = \"datasets/r/\"\n",
    "\n",
    "    # Construction de l'URL complète\n",
    "    url = f\"{base_api}{key_api}{dataset_id}\"\n",
    "\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as gz:\n",
    "        df = pd.read_csv(gz, sep = sep)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80d5dcb",
   "metadata": {},
   "source": [
    "## DAILY SWI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e896d707",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAMBX</th>\n",
       "      <th>LAMBY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRENEI</th>\n",
       "      <th>PRELIQ</th>\n",
       "      <th>T</th>\n",
       "      <th>FF</th>\n",
       "      <th>Q</th>\n",
       "      <th>DLI</th>\n",
       "      <th>SSI</th>\n",
       "      <th>...</th>\n",
       "      <th>RESR_NEIGE6</th>\n",
       "      <th>HTEURNEIGE</th>\n",
       "      <th>HTEURNEIGE6</th>\n",
       "      <th>HTEURNEIGEX</th>\n",
       "      <th>SNOW_FRAC</th>\n",
       "      <th>ECOULEMENT</th>\n",
       "      <th>WG_RACINE</th>\n",
       "      <th>WGI_RACINE</th>\n",
       "      <th>TINF_H</th>\n",
       "      <th>TSUP_H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>21079847</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20251027</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.5</td>\n",
       "      <td>2.4</td>\n",
       "      <td>6.076</td>\n",
       "      <td>2695.1</td>\n",
       "      <td>1376.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.1</td>\n",
       "      <td>20.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21079848</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20251028</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.1</td>\n",
       "      <td>15.4</td>\n",
       "      <td>2.1</td>\n",
       "      <td>7.500</td>\n",
       "      <td>2877.0</td>\n",
       "      <td>1195.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.2</td>\n",
       "      <td>22.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21079849</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20251029</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>17.0</td>\n",
       "      <td>2.9</td>\n",
       "      <td>9.242</td>\n",
       "      <td>3156.7</td>\n",
       "      <td>641.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>22.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21079850</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20251030</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.3</td>\n",
       "      <td>17.7</td>\n",
       "      <td>1.6</td>\n",
       "      <td>11.344</td>\n",
       "      <td>3426.6</td>\n",
       "      <td>178.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.205</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "      <td>18.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21079851</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20251031</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.4</td>\n",
       "      <td>17.9</td>\n",
       "      <td>1.6</td>\n",
       "      <td>11.022</td>\n",
       "      <td>3174.7</td>\n",
       "      <td>859.6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.207</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>21.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LAMBX  LAMBY      DATE  PRENEI  PRELIQ     T   FF       Q     DLI  \\\n",
       "21079847  11960  17450  20251027     0.0     0.0  15.5  2.4   6.076  2695.1   \n",
       "21079848  11960  17450  20251028     0.0     0.1  15.4  2.1   7.500  2877.0   \n",
       "21079849  11960  17450  20251029     0.0     1.0  17.0  2.9   9.242  3156.7   \n",
       "21079850  11960  17450  20251030     0.0     3.3  17.7  1.6  11.344  3426.6   \n",
       "21079851  11960  17450  20251031     0.0     0.4  17.9  1.6  11.022  3174.7   \n",
       "\n",
       "             SSI  ...  RESR_NEIGE6  HTEURNEIGE  HTEURNEIGE6  HTEURNEIGEX  \\\n",
       "21079847  1376.9  ...          0.0         0.0          0.0          0.0   \n",
       "21079848  1195.1  ...          0.0         0.0          0.0          0.0   \n",
       "21079849   641.0  ...          0.0         0.0          0.0          0.0   \n",
       "21079850   178.6  ...          0.0         0.0          0.0          0.0   \n",
       "21079851   859.6  ...          0.0         0.0          0.0          0.0   \n",
       "\n",
       "          SNOW_FRAC  ECOULEMENT  WG_RACINE  WGI_RACINE  TINF_H  TSUP_H  \n",
       "21079847        0.0         0.0      0.205         0.0    12.1    20.3  \n",
       "21079848        0.0         0.0      0.205         0.0    11.2    22.5  \n",
       "21079849        0.0         0.0      0.205         0.0    12.0    22.7  \n",
       "21079850        0.0         0.0      0.205         0.0    16.5    18.9  \n",
       "21079851        0.0         0.0      0.207         0.0    16.0    21.5  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quot_25 = recuperer_donnees_gz('92065ec0-ea6f-4f5e-8827-4344179c0a7f', 'QUOT_2020-2025', ';')\n",
    "quot_25.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "34672bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "liste_id=['eb0d6e42-cee6-4d7c-bc5b-646be4ced72e','33417617-c0dd-4513-804e-c3f563cb81b4','08ad5936-cb9e-4284-a6fc-36b29aca9607',\n",
    "          'ad584d65-7d2d-4ff1-bc63-4f93357ed196','10d2ce77-5c3b-44f8-bb46-4df27ed48595','da6cd598-498b-4e39-96ea-fae89a4a8a46',\n",
    "          '92065ec0-ea6f-4f5e-8827-4344179c0a7f','adcca99a-6db0-495a-869f-40c888174a57']\n",
    "# année=[1960-1969,1970-1979,1980-1989,'1990-1999',2000-2009,2010-2019,2020-202510,20251001-20251107]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aad819d3",
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate 7.00 GiB for an array with shape (26, 36135476) and data type float64",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[33], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m liste_df\u001b[38;5;241m=\u001b[39m[]\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m \u001b[38;5;28mid\u001b[39m \u001b[38;5;129;01min\u001b[39;00m liste_id:\n\u001b[1;32m----> 4\u001b[0m     data \u001b[38;5;241m=\u001b[39m recuperer_donnees_gz(\u001b[38;5;28mid\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      5\u001b[0m     liste_df\u001b[38;5;241m.\u001b[39mappend(data)\n\u001b[0;32m      6\u001b[0m daily_swi_df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mconcat(liste_df,ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mrecuperer_donnees_gz\u001b[1;34m(dataset_id, fichier_csv, sep)\u001b[0m\n\u001b[0;32m     26\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mGzipFile(fileobj\u001b[38;5;241m=\u001b[39mio\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent)) \u001b[38;5;28;01mas\u001b[39;00m gz:\n\u001b[1;32m---> 28\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(gz, sep \u001b[38;5;241m=\u001b[39m sep)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:626\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n\u001b[0;32m    625\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m parser:\n\u001b[1;32m--> 626\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\u001b[38;5;241m.\u001b[39mread(nrows)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1968\u001b[0m, in \u001b[0;36mTextFileReader.read\u001b[1;34m(self, nrows)\u001b[0m\n\u001b[0;32m   1965\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1966\u001b[0m         new_col_dict \u001b[38;5;241m=\u001b[39m col_dict\n\u001b[1;32m-> 1968\u001b[0m     df \u001b[38;5;241m=\u001b[39m DataFrame(\n\u001b[0;32m   1969\u001b[0m         new_col_dict,\n\u001b[0;32m   1970\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   1971\u001b[0m         index\u001b[38;5;241m=\u001b[39mindex,\n\u001b[0;32m   1972\u001b[0m         copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m using_copy_on_write(),\n\u001b[0;32m   1973\u001b[0m     )\n\u001b[0;32m   1975\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_currow \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m new_rows\n\u001b[0;32m   1976\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\core\\frame.py:778\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    772\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    773\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    774\u001b[0m     )\n\u001b[0;32m    776\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    777\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 778\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    779\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    780\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:503\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    499\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    500\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    501\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 503\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:152\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    149\u001b[0m axes \u001b[38;5;241m=\u001b[39m [columns, index]\n\u001b[0;32m    151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblock\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 152\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m create_block_manager_from_column_arrays(\n\u001b[0;32m    153\u001b[0m         arrays, axes, consolidate\u001b[38;5;241m=\u001b[39mconsolidate, refs\u001b[38;5;241m=\u001b[39mrefs\n\u001b[0;32m    154\u001b[0m     )\n\u001b[0;32m    155\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m typ \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    156\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m ArrayManager(arrays, [index, columns])\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2139\u001b[0m, in \u001b[0;36mcreate_block_manager_from_column_arrays\u001b[1;34m(arrays, axes, consolidate, refs)\u001b[0m\n\u001b[0;32m   2121\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcreate_block_manager_from_column_arrays\u001b[39m(\n\u001b[0;32m   2122\u001b[0m     arrays: \u001b[38;5;28mlist\u001b[39m[ArrayLike],\n\u001b[0;32m   2123\u001b[0m     axes: \u001b[38;5;28mlist\u001b[39m[Index],\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   2135\u001b[0m     \u001b[38;5;66;03m# These last three are sufficient to allow us to safely pass\u001b[39;00m\n\u001b[0;32m   2136\u001b[0m     \u001b[38;5;66;03m#  verify_integrity=False below.\u001b[39;00m\n\u001b[0;32m   2138\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 2139\u001b[0m         blocks \u001b[38;5;241m=\u001b[39m _form_blocks(arrays, consolidate, refs)\n\u001b[0;32m   2140\u001b[0m         mgr \u001b[38;5;241m=\u001b[39m BlockManager(blocks, axes, verify_integrity\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   2141\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2212\u001b[0m, in \u001b[0;36m_form_blocks\u001b[1;34m(arrays, consolidate, refs)\u001b[0m\n\u001b[0;32m   2209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(dtype\u001b[38;5;241m.\u001b[39mtype, (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mbytes\u001b[39m)):\n\u001b[0;32m   2210\u001b[0m     dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(\u001b[38;5;28mobject\u001b[39m)\n\u001b[1;32m-> 2212\u001b[0m values, placement \u001b[38;5;241m=\u001b[39m _stack_arrays(\u001b[38;5;28mlist\u001b[39m(tup_block), dtype)\n\u001b[0;32m   2213\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m is_dtlike:\n\u001b[0;32m   2214\u001b[0m     values \u001b[38;5;241m=\u001b[39m ensure_wrapped_if_datetimelike(values)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\core\\internals\\managers.py:2252\u001b[0m, in \u001b[0;36m_stack_arrays\u001b[1;34m(tuples, dtype)\u001b[0m\n\u001b[0;32m   2249\u001b[0m first \u001b[38;5;241m=\u001b[39m arrays[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m   2250\u001b[0m shape \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mlen\u001b[39m(arrays),) \u001b[38;5;241m+\u001b[39m first\u001b[38;5;241m.\u001b[39mshape\n\u001b[1;32m-> 2252\u001b[0m stacked \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(shape, dtype\u001b[38;5;241m=\u001b[39mdtype)\n\u001b[0;32m   2253\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, arr \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(arrays):\n\u001b[0;32m   2254\u001b[0m     stacked[i] \u001b[38;5;241m=\u001b[39m arr\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate 7.00 GiB for an array with shape (26, 36135476) and data type float64"
     ]
    }
   ],
   "source": [
    "#Fusion des tables\n",
    "liste_df=[]\n",
    "for id in liste_id:\n",
    "    data = recuperer_donnees_gz(id, '', ';')\n",
    "    liste_df.append(data)\n",
    "daily_swi_df=pd.concat(liste_df,ignore_index=True)\n",
    "daily_swi_df.shape(\n",
    "\n",
    ")\n",
    "# Ce code sort une erreur de mémoire, les bases sont trop lourdes pour pouvoir toutes les fusionnées."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1261157d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Création d'une colonne YEAR\n",
    "quot_25[\"YEAR\"] = quot_25[\"DATE\"].astype(str).str[:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57a9108",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "134"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quot_25[quot_25[\"YEAR\"]==2020][\"LAMBX\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d64f103c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  600,   760,   840,   920,  1000,  1080,  1160,  1240,  1320,\n",
       "        1400,  1480,  1560,  1640,  1720,  1800,  1880,  1960,  2040,\n",
       "        2120,  2200,  2280,  2360,  2440,  2520,  2600,  2680,  2760,\n",
       "        2840,  2920,  3000,  3080,  3160,  3240,  3320,  3400,  3480,\n",
       "        3560,  3640,  3720,  3800,  3880,  3960,  4040,  4120,  4200,\n",
       "        4280,  4360,  4440,  4520,  4600,  4680,  4760,  4840,  4920,\n",
       "        5000,  5080,  5160,  5240,  5320,  5400,  5480,  5560,  5640,\n",
       "        5720,  5800,  5880,  5960,  6040,  6120,  6200,  6280,  6360,\n",
       "        6440,  6520,  6600,  6680,  6760,  6840,  6920,  7000,  7080,\n",
       "        7160,  7240,  7320,  7400,  7480,  7560,  7640,  7720,  7800,\n",
       "        7880,  7960,  8040,  8120,  8200,  8280,  8360,  8440,  8520,\n",
       "        8600,  8680,  8760,  8840,  8920,  9000,  9080,  9160,  9240,\n",
       "        9320,  9400,  9480,  9560,  9640,  9720,  9800,  9880,  9960,\n",
       "       10040, 10120, 10200, 10280, 10360, 10440, 10520, 10600, 10680,\n",
       "       10760, 10840, 10920, 11000, 11080, 11160, 11240, 11320, 11400,\n",
       "       11480, 11560, 11640, 11720, 11800, 11880, 11960], dtype=int64)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quot_25[quot_25[\"YEAR\"]==2021][\"LAMBX\"].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "0a372ceb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LAMBX</th>\n",
       "      <th>LAMBY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>PRENEI</th>\n",
       "      <th>PRELIQ</th>\n",
       "      <th>T</th>\n",
       "      <th>FF</th>\n",
       "      <th>Q</th>\n",
       "      <th>DLI</th>\n",
       "      <th>SSI</th>\n",
       "      <th>...</th>\n",
       "      <th>RESR_NEIGE6</th>\n",
       "      <th>HTEURNEIGE</th>\n",
       "      <th>HTEURNEIGE6</th>\n",
       "      <th>HTEURNEIGEX</th>\n",
       "      <th>SNOW_FRAC</th>\n",
       "      <th>ECOULEMENT</th>\n",
       "      <th>WG_RACINE</th>\n",
       "      <th>WGI_RACINE</th>\n",
       "      <th>TINF_H</th>\n",
       "      <th>TSUP_H</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>36125579</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20191227</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>6.396</td>\n",
       "      <td>2714.8</td>\n",
       "      <td>503.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.328</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36125580</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20191228</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.7</td>\n",
       "      <td>2.3</td>\n",
       "      <td>4.937</td>\n",
       "      <td>2630.0</td>\n",
       "      <td>504.5</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.327</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.9</td>\n",
       "      <td>14.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36125581</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20191229</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.7</td>\n",
       "      <td>3.6</td>\n",
       "      <td>3.942</td>\n",
       "      <td>2371.0</td>\n",
       "      <td>841.1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.326</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.8</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36125582</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20191230</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.6</td>\n",
       "      <td>4.5</td>\n",
       "      <td>3.653</td>\n",
       "      <td>2338.6</td>\n",
       "      <td>972.9</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.324</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36125583</th>\n",
       "      <td>11960</td>\n",
       "      <td>17450</td>\n",
       "      <td>20191231</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.9</td>\n",
       "      <td>1.7</td>\n",
       "      <td>4.301</td>\n",
       "      <td>2418.4</td>\n",
       "      <td>849.8</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.322</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.4</td>\n",
       "      <td>12.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 29 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          LAMBX  LAMBY      DATE  PRENEI  PRELIQ     T   FF      Q     DLI  \\\n",
       "36125579  11960  17450  20191227     0.0     0.0  11.0  3.0  6.396  2714.8   \n",
       "36125580  11960  17450  20191228     0.0     0.0   9.7  2.3  4.937  2630.0   \n",
       "36125581  11960  17450  20191229     0.0     0.0   7.7  3.6  3.942  2371.0   \n",
       "36125582  11960  17450  20191230     0.0     0.0   9.6  4.5  3.653  2338.6   \n",
       "36125583  11960  17450  20191231     0.0     0.0   7.9  1.7  4.301  2418.4   \n",
       "\n",
       "            SSI  ...  RESR_NEIGE6  HTEURNEIGE  HTEURNEIGE6  HTEURNEIGEX  \\\n",
       "36125579  503.0  ...          0.0         0.0          0.0          0.0   \n",
       "36125580  504.5  ...          0.0         0.0          0.0          0.0   \n",
       "36125581  841.1  ...          0.0         0.0          0.0          0.0   \n",
       "36125582  972.9  ...          0.0         0.0          0.0          0.0   \n",
       "36125583  849.8  ...          0.0         0.0          0.0          0.0   \n",
       "\n",
       "          SNOW_FRAC  ECOULEMENT  WG_RACINE  WGI_RACINE  TINF_H  TSUP_H  \n",
       "36125579        0.0         0.0      0.328         0.0     9.6    15.0  \n",
       "36125580        0.0         0.0      0.327         0.0     6.9    14.1  \n",
       "36125581        0.0         0.0      0.326         0.0     5.8    12.9  \n",
       "36125582        0.0         0.0      0.324         0.0     6.0    12.9  \n",
       "36125583        0.0         0.0      0.322         0.0     4.4    12.8  \n",
       "\n",
       "[5 rows x 29 columns]"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quot_10_19 = recuperer_donnees_gz('da6cd598-498b-4e39-96ea-fae89a4a8a46', 'QUOT_2010-2019', ';')\n",
    "quot_10_19.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b123fae7",
   "metadata": {},
   "outputs": [],
   "source": [
    "quot_10_19[\"YEAR\"] = quot_10_19[\"DATE\"].astype(str).str[:4].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43dbc7b3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "142"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "quot_10_19[quot_10_19[\"YEAR\"]==2011][\"LAMBX\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45a24344",
   "metadata": {},
   "source": [
    "Il faudra repliquer la même chose sur toutes les bases depuis 1958, et fusionner toutes les bases en une seule complète de 1958 à 2025"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50050972",
   "metadata": {},
   "source": [
    "## SWI Uniforme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28a1ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.0-249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.1000-1249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.1250-1499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.1500-1749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.1750-1999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.2000-2249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.2250-2499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.250-499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.2500-2749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.2750-2999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.3000-3249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.3250-3499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.3500-3749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.3750-3999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.4000-4249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.4250-4499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.4500-4749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.4750-4999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.500-749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.5000-5249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.5250-5499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.5500-5749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.5750-5999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.6000-6249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.6250-6499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.6500-6749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.6750-6999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.7000-7249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.7250-7499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.750-999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.7500-7749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.7750-7999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.8000-8249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.8250-8499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.8500-8749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.8750-8999.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.9000-9249.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.9250-9499.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.9500-9749.csv\n",
      "Lecture : C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\\swi.9750-9999.csv\n",
      "Fusion terminée ✅\n",
      "(7005180, 5)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# chemin vers le dossier \n",
    "folder_path = \"C:/Users/lisaw/Desktop/ENSAE/3A/Machine_learning/Project/MACHINE-LEARNING-FOR-CLIMATE-RISK/Data_swi_uniform\"\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in os.listdir(folder_path):\n",
    "    if file.endswith(\".csv\"):\n",
    "        file_path = os.path.join(folder_path, file)\n",
    "        #print(\"Lecture :\", file_path)\n",
    "        df = pd.read_csv(file_path, sep=\";\")\n",
    "        dfs.append(df)\n",
    "\n",
    "swi_uniform_df = pd.concat(dfs, ignore_index=True)\n",
    "\n",
    "print(\"Fusion terminée\")\n",
    "print(swi_uniform_df.shape)\n",
    "\n",
    "#swi_uniform_df.to_csv(\"merged.csv\", index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "e11eb588",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>LAMBX</th>\n",
       "      <th>LAMBY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SWI_UNIF_MENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2</td>\n",
       "      <td>641374</td>\n",
       "      <td>7106309</td>\n",
       "      <td>196001</td>\n",
       "      <td>0,863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>641374</td>\n",
       "      <td>7106309</td>\n",
       "      <td>196002</td>\n",
       "      <td>0,876</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>641374</td>\n",
       "      <td>7106309</td>\n",
       "      <td>196003</td>\n",
       "      <td>0,856</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>641374</td>\n",
       "      <td>7106309</td>\n",
       "      <td>196004</td>\n",
       "      <td>0,757</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>641374</td>\n",
       "      <td>7106309</td>\n",
       "      <td>196005</td>\n",
       "      <td>0,673</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   NUMERO   LAMBX    LAMBY    DATE SWI_UNIF_MENS\n",
       "0       2  641374  7106309  196001         0,863\n",
       "1       2  641374  7106309  196002         0,876\n",
       "2       2  641374  7106309  196003         0,856\n",
       "3       2  641374  7106309  196004         0,757\n",
       "4       2  641374  7106309  196005         0,673"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_uniform_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4e31ae82",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>NUMERO</th>\n",
       "      <th>LAMBX</th>\n",
       "      <th>LAMBY</th>\n",
       "      <th>DATE</th>\n",
       "      <th>SWI_UNIF_MENS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [NUMERO, LAMBX, LAMBY, DATE, SWI_UNIF_MENS]\n",
       "Index: []"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "swi_uniform_df[swi_uniform_df[\"LAMBX\"]==11960]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "595e87fa",
   "metadata": {},
   "source": [
    "## Données BRGM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f3f98664",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Base de données BRGM\n",
    "\n",
    "def recuperer_donnees_7z(dataset_id, fichier_csv, sep):\n",
    "    \"\"\"\n",
    "    Cette fonction télécharge les données d'un fichier CSV.GZ à partir d'une URL et les charge dans un DataFrame pandas.\n",
    "    \n",
    "    Paramètres:\n",
    "    dataset_id (str): identifiant du fichier CSV.GZ.\n",
    "    fichier_csv (str): Le nom du fichier CSV.GZ à enregistrer localement.\n",
    "    sep ( str ) : le séparateur à utiliser\n",
    "    \n",
    "    Retourne:\n",
    "    DataFrame: Un DataFrame pandas contenant les données du fichier CSV.\n",
    "    \"\"\"\n",
    "\n",
    "    # URL de base pour accéder à l'API\n",
    "    base_api = \"https://www.data.gouv.fr/api/1/\"\n",
    "\n",
    "    # Chemin pour accéder aux enregistrements du dataset\n",
    "    key_api = \"datasets/r/\"\n",
    "\n",
    "    # Construction de l'URL complète\n",
    "    url = f\"{base_api}{key_api}{dataset_id}\"\n",
    "\n",
    "\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    with gzip.GzipFile(fileobj=io.BytesIO(response.content)) as gz:\n",
    "        df = pd.read_csv(gz, sep = sep)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "153acb82",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import requests\n",
    "import py7zr\n",
    "import pandas as pd\n",
    "from io import BytesIO\n",
    "import tempfile\n",
    "\n",
    "def load_7z_to_dataframe(url: str, csv_only=True):\n",
    "    \"\"\"\n",
    "    Télécharge un fichier .7z depuis une URL, l'extrait,\n",
    "    puis concatène les CSV trouvés en un DataFrame unique.\n",
    "    \n",
    "    Paramètres\n",
    "    ----------\n",
    "    url : str\n",
    "        Lien de téléchargement du fichier .7z\n",
    "    csv_only : bool\n",
    "        Si True, charge uniquement les .csv\n",
    "        \n",
    "    Retour\n",
    "    ------\n",
    "    pd.DataFrame\n",
    "    \"\"\"\n",
    "    \n",
    "    # === 1) Télécharger le fichier ===\n",
    "    print(\"Téléchargement du fichier .7z...\")\n",
    "    response = requests.get(url)\n",
    "    \n",
    "    if response.status_code != 200:\n",
    "        raise Exception(\"❌ Erreur de téléchargement :\", response.status_code)\n",
    "    \n",
    "    # Stocker dans un buffer mémoire\n",
    "    file_content = BytesIO(response.content)\n",
    "    \n",
    "    # === 2) Créer un dossier temporaire ===\n",
    "    tmp_dir = tempfile.mkdtemp()\n",
    "    \n",
    "    # === 3) Extraire le fichier .7z ===\n",
    "    print(\"Extraction...\")\n",
    "    with py7zr.SevenZipFile(file_content, mode='r') as z:\n",
    "        z.extractall(path=tmp_dir)\n",
    "    \n",
    "    print(f\"✅ Extraction dans : {tmp_dir}\")\n",
    "\n",
    "    # === 4) Charger tous les fichiers CSV en DataFrame ===\n",
    "    dfs = []\n",
    "    for root, _, files in os.walk(tmp_dir):\n",
    "        for f in files:\n",
    "            if not csv_only or f.endswith(\".csv\"):\n",
    "                filepath = os.path.join(root, f)\n",
    "                print(\"Lecture :\", filepath)\n",
    "\n",
    "                try:\n",
    "                    df = pd.read_csv(filepath)\n",
    "                    dfs.append(df)\n",
    "                except Exception as e:\n",
    "                    print(f\"Erreur lecture {f} → ignoré : {e}\")\n",
    "\n",
    "    if not dfs:\n",
    "        raise Exception(\"❌ Aucun CSV trouvé dans l’archive\")\n",
    "\n",
    "    # === 5) Fusionner en un DataFrame unique ===\n",
    "    final_df = pd.concat(dfs, ignore_index=True)\n",
    "    print(\"✅ Fusion terminée !\")\n",
    "\n",
    "    return final_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8cbb9f86",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Téléchargement du fichier .7z...\n",
      "Extraction...\n",
      "✅ Extraction dans : C:\\Users\\lisaw\\AppData\\Local\\Temp\\tmp88dpvy17\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "❌ Aucun CSV trouvé dans l’archive",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mException\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[37], line 3\u001b[0m\n\u001b[0;32m      1\u001b[0m url \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhttps://www.data.gouv.fr/api/1/datasets/r/c944be1e-06d6-46be-bf7d-9f9ad2b8ced9\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m----> 3\u001b[0m df \u001b[38;5;241m=\u001b[39m load_7z_to_dataframe(url)\n\u001b[0;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(df\u001b[38;5;241m.\u001b[39mhead())\n",
      "Cell \u001b[1;32mIn[36], line 60\u001b[0m, in \u001b[0;36mload_7z_to_dataframe\u001b[1;34m(url, csv_only)\u001b[0m\n\u001b[0;32m     57\u001b[0m                 \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mErreur lecture \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mf\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m → ignoré : \u001b[39m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     59\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m dfs:\n\u001b[1;32m---> 60\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m❌ Aucun CSV trouvé dans l’archive\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     62\u001b[0m \u001b[38;5;66;03m# === 5) Fusionner en un DataFrame unique ===\u001b[39;00m\n\u001b[0;32m     63\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat(dfs, ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mException\u001b[0m: ❌ Aucun CSV trouvé dans l’archive"
     ]
    }
   ],
   "source": [
    "url = \"https://www.data.gouv.fr/api/1/datasets/r/c944be1e-06d6-46be-bf7d-9f9ad2b8ced9\"\n",
    "\n",
    "df = load_7z_to_dataframe(url)\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c62bd8cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "BadGzipFile",
     "evalue": "Not a gzipped file (b'7z')",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mBadGzipFile\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m data_BRGM \u001b[38;5;241m=\u001b[39m recuperer_donnees_gz(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mc944be1e-06d6-46be-bf7d-9f9ad2b8ced9\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mBRGM_argile\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m;\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      2\u001b[0m data_BRGM\u001b[38;5;241m.\u001b[39mtail()\n",
      "Cell \u001b[1;32mIn[3], line 28\u001b[0m, in \u001b[0;36mrecuperer_donnees_gz\u001b[1;34m(dataset_id, fichier_csv, sep)\u001b[0m\n\u001b[0;32m     26\u001b[0m response\u001b[38;5;241m.\u001b[39mraise_for_status()\n\u001b[0;32m     27\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m gzip\u001b[38;5;241m.\u001b[39mGzipFile(fileobj\u001b[38;5;241m=\u001b[39mio\u001b[38;5;241m.\u001b[39mBytesIO(response\u001b[38;5;241m.\u001b[39mcontent)) \u001b[38;5;28;01mas\u001b[39;00m gz:\n\u001b[1;32m---> 28\u001b[0m     df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_csv(gz, sep \u001b[38;5;241m=\u001b[39m sep)\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m df\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[1;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[0;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[0;32m   1014\u001b[0m     dialect,\n\u001b[0;32m   1015\u001b[0m     delimiter,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[0;32m   1023\u001b[0m )\n\u001b[0;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[1;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _read(filepath_or_buffer, kwds)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[1;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[0;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[0;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[1;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m TextFileReader(filepath_or_buffer, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[0;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[1;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[0;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_make_engine(f, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mengine)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\readers.py:1898\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[1;34m(self, f, engine)\u001b[0m\n\u001b[0;32m   1895\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(msg)\n\u001b[0;32m   1897\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1898\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m mapping[engine](f, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions)\n\u001b[0;32m   1899\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:\n\u001b[0;32m   1900\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\site-packages\\pandas\\io\\parsers\\c_parser_wrapper.py:93\u001b[0m, in \u001b[0;36mCParserWrapper.__init__\u001b[1;34m(self, src, **kwds)\u001b[0m\n\u001b[0;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype_backend\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     91\u001b[0m     \u001b[38;5;66;03m# Fail here loudly instead of in cython after reading\u001b[39;00m\n\u001b[0;32m     92\u001b[0m     import_optional_dependency(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpyarrow\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 93\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader \u001b[38;5;241m=\u001b[39m parsers\u001b[38;5;241m.\u001b[39mTextReader(src, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwds)\n\u001b[0;32m     95\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39munnamed_cols \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reader\u001b[38;5;241m.\u001b[39munnamed_cols\n\u001b[0;32m     97\u001b[0m \u001b[38;5;66;03m# error: Cannot determine type of 'names'\u001b[39;00m\n",
      "File \u001b[1;32mparsers.pyx:574\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader.__cinit__\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:663\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._get_header\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:874\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._tokenize_rows\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:891\u001b[0m, in \u001b[0;36mpandas._libs.parsers.TextReader._check_tokenize_status\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mparsers.pyx:2053\u001b[0m, in \u001b[0;36mpandas._libs.parsers.raise_parser_error\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\gzip.py:337\u001b[0m, in \u001b[0;36mGzipFile.read1\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    335\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m size \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m    336\u001b[0m     size \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mDEFAULT_BUFFER_SIZE\n\u001b[1;32m--> 337\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_buffer\u001b[38;5;241m.\u001b[39mread1(size)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\_compression.py:68\u001b[0m, in \u001b[0;36mDecompressReader.readinto\u001b[1;34m(self, b)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreadinto\u001b[39m(\u001b[38;5;28mself\u001b[39m, b):\n\u001b[0;32m     67\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mmemoryview\u001b[39m(b) \u001b[38;5;28;01mas\u001b[39;00m view, view\u001b[38;5;241m.\u001b[39mcast(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mB\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m byte_view:\n\u001b[1;32m---> 68\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mread(\u001b[38;5;28mlen\u001b[39m(byte_view))\n\u001b[0;32m     69\u001b[0m         byte_view[:\u001b[38;5;28mlen\u001b[39m(data)] \u001b[38;5;241m=\u001b[39m data\n\u001b[0;32m     70\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(data)\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\gzip.py:527\u001b[0m, in \u001b[0;36m_GzipReader.read\u001b[1;34m(self, size)\u001b[0m\n\u001b[0;32m    523\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_new_member:\n\u001b[0;32m    524\u001b[0m     \u001b[38;5;66;03m# If the _new_member flag is set, we have to\u001b[39;00m\n\u001b[0;32m    525\u001b[0m     \u001b[38;5;66;03m# jump to the next member, if there is one.\u001b[39;00m\n\u001b[0;32m    526\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_read()\n\u001b[1;32m--> 527\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_read_gzip_header():\n\u001b[0;32m    528\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pos\n\u001b[0;32m    529\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\gzip.py:496\u001b[0m, in \u001b[0;36m_GzipReader._read_gzip_header\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    495\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_read_gzip_header\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m--> 496\u001b[0m     last_mtime \u001b[38;5;241m=\u001b[39m _read_gzip_header(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_fp)\n\u001b[0;32m    497\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m last_mtime \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    498\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\lisaw\\anaconda3\\Lib\\gzip.py:456\u001b[0m, in \u001b[0;36m_read_gzip_header\u001b[1;34m(fp)\u001b[0m\n\u001b[0;32m    453\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    455\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m magic \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124mb\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\037\u001b[39;00m\u001b[38;5;130;01m\\213\u001b[39;00m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m--> 456\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m BadGzipFile(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mNot a gzipped file (\u001b[39m\u001b[38;5;132;01m%r\u001b[39;00m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;241m%\u001b[39m magic)\n\u001b[0;32m    458\u001b[0m (method, flag, last_mtime) \u001b[38;5;241m=\u001b[39m struct\u001b[38;5;241m.\u001b[39munpack(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<BBIxx\u001b[39m\u001b[38;5;124m\"\u001b[39m, _read_exact(fp, \u001b[38;5;241m8\u001b[39m))\n\u001b[0;32m    459\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m method \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m8\u001b[39m:\n",
      "\u001b[1;31mBadGzipFile\u001b[0m: Not a gzipped file (b'7z')"
     ]
    }
   ],
   "source": [
    "data_BRGM = recuperer_donnees_gz('c944be1e-06d6-46be-bf7d-9f9ad2b8ced9', 'BRGM_argile', ';')\n",
    "data_BRGM.tail()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
